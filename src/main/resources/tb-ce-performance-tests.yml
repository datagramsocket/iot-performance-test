#
# Copyright Â© 2016-2018 The Thingsboard Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

server:
  # Server bind address
  address: "0.0.0.0"
  # Server bind port
  port: "${SERVER_PORT:19090}"

rest:
  url: "${REST_URL:http://10.82.13.112:8081}"
  username: "${REST_USERNAME:97413487@qq.com}"
  password: "${REST_PASSWORD:123456}"
http:
  base_url: "${HTTP_BASE_URL:http://10.82.13.112:8833}"
  test_url: "${HTTP_TEST_URL:}"
mqtt:
  host: "${MQTT_HOST:10.82.27.140}"
  port: "${MQTT_PORT:1883}"
  ssl:
    enabled: "${MQTT_SSL_ENABLED:false}"
    key_store: "${MQTT_SSL_KEY_STORE:mqttclient.jks}"
    key_store_password: "${MQTT_SSL_KEY_STORE_PASSWORD:password}"
  publishTopic: "${MQTT_PUBLISH_TOPIC:}"
  #0:AT_MOST_ONCE,1:AT_LEAST_ONCE,2:EXACTLY_ONCE,128:FAILURE
  qos: "${MQTT_QOS:1}"
device:
  # Device API to use - MQTT or HTTP
  api: "${DEVICE_API:MQTT}"
  startIdx: "${DEVICE_START_IDX:0}"
  endIdx: "${DEVICE_END_IDX:25}"
  count: "${DEVICE_COUNT:25}" # count of devices to be used by clients in k8s deployment run
  createOnStart: "${DEVICE_CREATE_ON_START:false}"
  deleteOnComplete: "${DEVICE_DELETE_ON_COMPLETE:false}"
gateway:
  startIdx: "${GATEWAY_START_IDX:0}"
  endIdx: "${GATEWAY_END_IDX:3}"
  count: "${GATEWAY_COUNT:3}" # count of devices to be used by clients in k8s deployment run
  createOnStart: "${GATEWAY_CREATE_ON_START:true}"
  deleteOnComplete: "${GATEWAY_DELETE_ON_COMPLETE:false}"
customer:
  startIdx: "${CUSTOMER_START_IDX:0}"
  endIdx: "${CUSTOMER_END_IDX:0}"
  createOnStart: "${CUSTOMER_CREATE_ON_START:false}"
  deleteOnComplete: "${CUSTOMER_DELETE_ON_COMPLETE:false}"
dashboard:
  createOnStart: "${DASHBOARD_CREATE_ON_START:false}"
  deleteOnComplete: "${DASHBOARD_DELETE_ON_COMPLETE:false}"
  deleteIfExists: "${DASHBOARD_DELETE_IF_EXISTS:false}"
  tenant: alarms.json # please use comma separated list for multiple dashboards: dashboard1.json, dashboard2.json
  shared: "devices.json"
warmup:
  enabled: "${WARMUP_ENABLED:false}"
test:
  # Type of the payload to send: CUSTOM, SMART_TRACKER, SMART_METER
  # CUSTOM - use the keyname:keytype format in customPayload
  # RANDOM - TODO: add description
  # SMART_TRACKER - sample payload: {"latitude": 42.222222, "longitude": 73.333333, "speed": 55.5, "fuel": 92, "batteryLevel": 81}
  # SMART_METER - sample payload: {"pulseCounter": 1234567, "leakage": false, "batteryLevel": 81}
  payloadType: "${TEST_PAYLOAD_TYPE:CUSTOM}"
  # format is: key1:int,key2:double,key3:boolean,key4:string,key5:time,key6:float
  customPayload: "${TEST_CUSTOM_PAYLOAD:key1:int}"
  instanceIdx: "${INSTANCE_IDX:0}"
  useInstanceIdx: "${USE_INSTANCE_IDX:false}"
  useInstanceIdxRegex: "${USE_INSTANCE_IDX_REGEX:false}"
  instanceIdxRegexSource: "${INSTANCE_IDX_REGEX_SOURCE:}"
  instanceIdxRegex: "${INSTANCE_IDX_REGEX:([0-9]+)$}"
  enabled: "${TEST_ENABLED:true}"
  updateRootRuleChain: "${UPDATE_ROOT_RULE_CHAIN:false}"
  revertRootRuleChain: "${REVERT_ROOT_RULE_CHAIN:false}"
  # Test API to use - device or gateway
  api: "${TEST_API:device}"
  sequential: "${TEST_SEQUENTIAL:true}"
  ruleChainName:  "${RULE_CHAIN_NAME:root_rule_chain_ce.json}"
  # messages per second.
  telemetry: "${TEST_TELEMETRY:true}"
  mps: "${MESSAGES_PER_SECOND:100}"
  duration: "${DURATION_IN_SECONDS:10}"
  statSampleInterval: "${SAMPLE_INTERVAL_IN_SECONDS:1}"
  alarms:
    start: "${ALARM_STORM_START_SECOND:0}"
    end: "${ALARM_STORM_END_SECOND:0}"
    # alarms per second should be less them messages per second.
    aps: "${ALARMS_PER_SECOND:10}"
  testeval: "${TEST_JS_TESTEVAL:true}"
  testevalCount: "${TEST_JS_TESTEVAL_COUNT:10000}"
  scheduler_thread_pool_size: "${TEST_SCHEDULER_THREAD_POOL_SIZE:10}"
  worker_thread_pool_size: "${TEST_WORKER_THREAD_POOL_SIZE:10}"

queue:
  type: "${TB_QUEUE_TYPE:kafka}" # in-memory or kafka (Apache Kafka) or aws-sqs (AWS SQS) or pubsub (PubSub) or service-bus (Azure Service Bus) or rabbitmq (RabbitMQ)
  kafka:
    bootstrap.servers: "${TB_KAFKA_SERVERS:10.82.13.110:9092}"
    acks: "${TB_KAFKA_ACKS:all}"
    retries: "${TB_KAFKA_RETRIES:1}"
    batch.size: "${TB_KAFKA_BATCH_SIZE:16384}"
    linger.ms: "${TB_KAFKA_LINGER_MS:1}"
    buffer.memory: "${TB_BUFFER_MEMORY:33554432}"
    replication_factor: "${TB_QUEUE_KAFKA_REPLICATION_FACTOR:1}"
    max_poll_records: "${TB_QUEUE_KAFKA_MAX_POLL_RECORDS:8192}"
    max_partition_fetch_bytes: "${TB_QUEUE_KAFKA_MAX_PARTITION_FETCH_BYTES:16777216}"
    fetch_max_bytes: "${TB_QUEUE_KAFKA_FETCH_MAX_BYTES:134217728}"
    topic-properties:
      rule-engine: "${TB_QUEUE_KAFKA_RE_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000}"
      core: "${TB_QUEUE_KAFKA_CORE_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000}"
      transport-api: "${TB_QUEUE_KAFKA_TA_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000}"
      notifications: "${TB_QUEUE_KAFKA_NOTIFICATIONS_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000}"
      js-executor: "${TB_QUEUE_KAFKA_JE_TOPIC_PROPERTIES:retention.ms:604800000;segment.bytes:26214400;retention.bytes:104857600}"
  js:
    # JS Eval request topic
    request_topic: "${REMOTE_JS_EVAL_REQUEST_TOPIC:js_eval.requests}"
    # JS Eval responses topic prefix that is combined with node id
    response_topic_prefix: "${REMOTE_JS_EVAL_RESPONSE_TOPIC:js_eval.responses}"
    # JS Eval max pending requests
    max_pending_requests: "${REMOTE_JS_MAX_PENDING_REQUESTS:10000}"
    # JS Eval max request timeout
    max_eval_requests_timeout: "${REMOTE_JS_MAX_EVAL_REQUEST_TIMEOUT:60000}"
    # JS max request timeout
    max_requests_timeout: "${REMOTE_JS_MAX_REQUEST_TIMEOUT:10000}"
    # JS response poll interval
    response_poll_interval: "${REMOTE_JS_RESPONSE_POLL_INTERVAL_MS:25}"
    # JS response auto commit interval
    response_auto_commit_interval: "${REMOTE_JS_RESPONSE_AUTO_COMMIT_INTERVAL_MS:100}"
  transport_api:
    requests_topic: "${TB_QUEUE_TRANSPORT_API_REQUEST_TOPIC:tb_transport.api.requests}"
    responses_topic: "${TB_QUEUE_TRANSPORT_API_RESPONSE_TOPIC:tb_transport.api.responses}"
    max_pending_requests: "${TB_QUEUE_TRANSPORT_MAX_PENDING_REQUESTS:10000}"
    max_requests_timeout: "${TB_QUEUE_TRANSPORT_MAX_REQUEST_TIMEOUT:10000}"
    max_callback_threads: "${TB_QUEUE_TRANSPORT_MAX_CALLBACK_THREADS:100}"
    request_poll_interval: "${TB_QUEUE_TRANSPORT_REQUEST_POLL_INTERVAL_MS:25}"
    response_poll_interval: "${TB_QUEUE_TRANSPORT_RESPONSE_POLL_INTERVAL_MS:25}"
  core:
    topic: "${TB_QUEUE_CORE_TOPIC:tb_core}"
    poll-interval: "${TB_QUEUE_CORE_POLL_INTERVAL_MS:25}"
    partitions: "${TB_QUEUE_CORE_PARTITIONS:10}"
    pack-processing-timeout: "${TB_QUEUE_CORE_PACK_PROCESSING_TIMEOUT_MS:2000}"
    stats:
      enabled: "${TB_QUEUE_CORE_STATS_ENABLED:true}"
      print-interval-ms: "${TB_QUEUE_CORE_STATS_PRINT_INTERVAL_MS:60000}"
  rule-engine:
    topic: "${TB_QUEUE_RULE_ENGINE_TOPIC:tb_rule_engine}"
    poll-interval: "${TB_QUEUE_RULE_ENGINE_POLL_INTERVAL_MS:25}"
    pack-processing-timeout: "${TB_QUEUE_RULE_ENGINE_PACK_PROCESSING_TIMEOUT_MS:2000}"
    stats:
      enabled: "${TB_QUEUE_RULE_ENGINE_STATS_ENABLED:true}"
      print-interval-ms: "${TB_QUEUE_RULE_ENGINE_STATS_PRINT_INTERVAL_MS:60000}"
    queues:
      - name: "${TB_QUEUE_RE_MAIN_QUEUE_NAME:Main}"
        topic: "${TB_QUEUE_RE_MAIN_TOPIC:tb_rule_engine.main}"
        poll-interval: "${TB_QUEUE_RE_MAIN_POLL_INTERVAL_MS:25}"
        partitions: "${TB_QUEUE_RE_MAIN_PARTITIONS:10}"
        pack-processing-timeout: "${TB_QUEUE_RE_MAIN_PACK_PROCESSING_TIMEOUT_MS:2000}"
        submit-strategy:
          type: "${TB_QUEUE_RE_MAIN_SUBMIT_STRATEGY_TYPE:BURST}" # BURST, BATCH, SEQUENTIAL_BY_ORIGINATOR, SEQUENTIAL_BY_TENANT, SEQUENTIAL
          # For BATCH only
          batch-size: "${TB_QUEUE_RE_MAIN_SUBMIT_STRATEGY_BATCH_SIZE:1000}" # Maximum number of messages in batch
        processing-strategy:
          type: "${TB_QUEUE_RE_MAIN_PROCESSING_STRATEGY_TYPE:SKIP_ALL_FAILURES}" # SKIP_ALL_FAILURES, RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          # For RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          retries: "${TB_QUEUE_RE_MAIN_PROCESSING_STRATEGY_RETRIES:3}" # Number of retries, 0 is unlimited
          failure-percentage: "${TB_QUEUE_RE_MAIN_PROCESSING_STRATEGY_FAILURE_PERCENTAGE:0}" # Skip retry if failures or timeouts are less then X percentage of messages;
          pause-between-retries: "${TB_QUEUE_RE_MAIN_PROCESSING_STRATEGY_RETRY_PAUSE:3}"# Time in seconds to wait in consumer thread before retries;
      - name: "${TB_QUEUE_RE_HP_QUEUE_NAME:HighPriority}"
        topic: "${TB_QUEUE_RE_HP_TOPIC:tb_rule_engine.hp}"
        poll-interval: "${TB_QUEUE_RE_HP_POLL_INTERVAL_MS:25}"
        partitions: "${TB_QUEUE_RE_HP_PARTITIONS:10}"
        pack-processing-timeout: "${TB_QUEUE_RE_HP_PACK_PROCESSING_TIMEOUT_MS:2000}"
        submit-strategy:
          type: "${TB_QUEUE_RE_HP_SUBMIT_STRATEGY_TYPE:BURST}" # BURST, BATCH, SEQUENTIAL_BY_ORIGINATOR, SEQUENTIAL_BY_TENANT, SEQUENTIAL
          # For BATCH only
          batch-size: "${TB_QUEUE_RE_HP_SUBMIT_STRATEGY_BATCH_SIZE:100}" # Maximum number of messages in batch
        processing-strategy:
          type: "${TB_QUEUE_RE_HP_PROCESSING_STRATEGY_TYPE:RETRY_FAILED_AND_TIMED_OUT}" # SKIP_ALL_FAILURES, RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          # For RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          retries: "${TB_QUEUE_RE_HP_PROCESSING_STRATEGY_RETRIES:0}" # Number of retries, 0 is unlimited
          failure-percentage: "${TB_QUEUE_RE_HP_PROCESSING_STRATEGY_FAILURE_PERCENTAGE:0}" # Skip retry if failures or timeouts are less then X percentage of messages;
          pause-between-retries: "${TB_QUEUE_RE_HP_PROCESSING_STRATEGY_RETRY_PAUSE:5}"# Time in seconds to wait in consumer thread before retries;
      - name: "${TB_QUEUE_RE_SQ_QUEUE_NAME:SequentialByOriginator}"
        topic: "${TB_QUEUE_RE_SQ_TOPIC:tb_rule_engine.sq}"
        poll-interval: "${TB_QUEUE_RE_SQ_POLL_INTERVAL_MS:25}"
        partitions: "${TB_QUEUE_RE_SQ_PARTITIONS:10}"
        pack-processing-timeout: "${TB_QUEUE_RE_SQ_PACK_PROCESSING_TIMEOUT_MS:2000}"
        submit-strategy:
          type: "${TB_QUEUE_RE_SQ_SUBMIT_STRATEGY_TYPE:SEQUENTIAL_BY_ORIGINATOR}" # BURST, BATCH, SEQUENTIAL_BY_ORIGINATOR, SEQUENTIAL_BY_TENANT, SEQUENTIAL
          # For BATCH only
          batch-size: "${TB_QUEUE_RE_SQ_SUBMIT_STRATEGY_BATCH_SIZE:100}" # Maximum number of messages in batch
        processing-strategy:
          type: "${TB_QUEUE_RE_SQ_PROCESSING_STRATEGY_TYPE:RETRY_FAILED_AND_TIMED_OUT}" # SKIP_ALL_FAILURES, RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          # For RETRY_ALL, RETRY_FAILED, RETRY_TIMED_OUT, RETRY_FAILED_AND_TIMED_OUT
          retries: "${TB_QUEUE_RE_SQ_PROCESSING_STRATEGY_RETRIES:3}" # Number of retries, 0 is unlimited
          failure-percentage: "${TB_QUEUE_RE_SQ_PROCESSING_STRATEGY_FAILURE_PERCENTAGE:0}" # Skip retry if failures or timeouts are less then X percentage of messages;
          pause-between-retries: "${TB_QUEUE_RE_SQ_PROCESSING_STRATEGY_RETRY_PAUSE:5}"# Time in seconds to wait in consumer thread before retries;
  transport:
    # For high priority notifications that require minimum latency and processing time
    notifications_topic: "${TB_QUEUE_TRANSPORT_NOTIFICATIONS_TOPIC:tb_transport.notifications}"
    poll_interval: "${TB_QUEUE_CORE_POLL_INTERVAL_MS:25}"

js:
  evaluator: "${JS_EVALUATOR:local}" # local/remote
  # Built-in JVM JavaScript environment properties
  script_type: "${JS_SCRIPT_TYPE:CONVERTER_UP_LINK_SCRIPT}"
  script_param_file: "${JS_SCRIPT_PARAM_FILE:UpLinkScriptV2831param.json}"
  local:
    # Use Sandboxed (secured) JVM JavaScript environment
    use_js_sandbox: "${USE_LOCAL_JS_SANDBOX:false}"
    # Specify thread pool size for JavaScript sandbox resource monitor
    monitor_thread_pool_size: "${LOCAL_JS_SANDBOX_MONITOR_THREAD_POOL_SIZE:4}"
    # Maximum CPU time in milliseconds allowed for script execution
    max_cpu_time: "${LOCAL_JS_SANDBOX_MAX_CPU_TIME:10000}"
    # Maximum allowed JavaScript execution errors before JavaScript will be blacklisted
    max_errors: "${LOCAL_JS_SANDBOX_MAX_ERRORS:3}"
    # JS Eval max request timeout. 0 - no timeout
    max_requests_timeout: "${LOCAL_JS_MAX_REQUEST_TIMEOUT:0}"
    # Maximum time in seconds for black listed function to stay in the list.
    max_black_list_duration_sec: "${LOCAL_JS_SANDBOX_MAX_BLACKLIST_DURATION_SEC:3}"
    stats:
      enabled: "${TB_JS_LOCAL_STATS_ENABLED:true}"
      print_interval_ms: "${TB_JS_LOCAL_STATS_PRINT_INTERVAL_MS:1000}"
  # Remote JavaScript environment properties
  remote:
    # Maximum allowed JavaScript execution errors before JavaScript will be blacklisted
    max_errors: "${REMOTE_JS_SANDBOX_MAX_ERRORS:3}"
    # Maximum time in seconds for black listed function to stay in the list.
    max_black_list_duration_sec: "${REMOTE_JS_SANDBOX_MAX_BLACKLIST_DURATION_SEC:3}"
    stats:
      enabled: "${TB_JS_REMOTE_STATS_ENABLED:true}"
      print_interval_ms: "${TB_JS_REMOTE_STATS_PRINT_INTERVAL_MS:1000}"

service:
  type: "${TB_SERVICE_TYPE:tb-rule-engine}" # monolith or tb-core or tb-rule-engine
  # Unique id for this service (autogenerated if empty)
  id: "${TB_SERVICE_ID:}"
  transport_type: "${TB_TRANSPORT_TYPE:mqtt}" #transport type

# SQL DAO Configuration
spring:
  data:
    jpa:
      repositories:
        enabled: "true"
  jpa:
#    properties:
    open-in-view: "false"
    hibernate:
      ddl-auto: "none"
    database-platform: "${SPRING_JPA_DATABASE_PLATFORM:org.hibernate.dialect.PostgreSQLDialect}"
  datasource:
    driverClassName: "${SPRING_DRIVER_CLASS_NAME:org.postgresql.Driver}"
    url: "${SPRING_DATASOURCE_URL:jdbc:postgresql://10.82.13.110:5432/infinovaiot}"
    username: "${SPRING_DATASOURCE_USERNAME:postgres}"
    password: "${SPRING_DATASOURCE_PASSWORD:root}"
    hikari:
      maximumPoolSize: "${SPRING_DATASOURCE_MAXIMUM_POOL_SIZE:5}"

# Security parameters
security:
  # JWT Token parameters
  jwt:
    tokenExpirationTime: "${JWT_TOKEN_EXPIRATION_TIME:9000}" # Number of seconds (2.5 hours)
    refreshTokenExpTime: "${JWT_REFRESH_TOKEN_EXPIRATION_TIME:604800}" # Number of seconds (1 week)
    tokenIssuer: "${JWT_TOKEN_ISSUER:thingsboard.io}"
    tokenSigningKey: "${JWT_TOKEN_SIGNING_KEY:thingsboardDefaultSigningKey}"
  # Enable/disable access to Tenant Administrators JWT token by System Administrator or Customer Users JWT token by Tenant Administrator
  user_token_access_enabled: "${SECURITY_USER_TOKEN_ACCESS_ENABLED:true}"
  # Enable/disable case-sensitive username login
  user_login_case_sensitive: "${SECURITY_USER_LOGIN_CASE_SENSITIVE:true}"
  claim:
    # Enable/disable claiming devices, if false -> the device's [claimingAllowed] SERVER_SCOPE attribute must be set to [true] to allow claiming specific device
    allowClaimingByDefault: "${SECURITY_CLAIM_ALLOW_CLAIMING_BY_DEFAULT:true}"
    # Time allowed to claim the device in milliseconds
    duration: "${SECURITY_CLAIM_DURATION:60000}" # 1 minute, note this value must equal claimDevices.timeToLiveInMinutes value
  basic:
    enabled: "${SECURITY_BASIC_ENABLED:false}"
  oauth2:
    # Enable/disable OAuth 2 login functionality
    # For details please refer to https://thingsboard.io/docs/user-guide/oauth-2-support/
    enabled: "${SECURITY_OAUTH2_ENABLED:false}"
    # Redirect URL where access code from external user management system will be processed
    loginProcessingUrl: "${SECURITY_OAUTH2_LOGIN_PROCESSING_URL:/login/oauth2/code/}"
    # List of SSO clients
    clients:
      default:
        # Label that going to be show on login button - 'Login with {loginButtonLabel}'
        loginButtonLabel: "${SECURITY_OAUTH2_DEFAULT_LOGIN_BUTTON_LABEL:Default}"
        # Icon that going to be show on login button. Material design icon ID (https://material.angularjs.org/latest/api/directive/mdIcon)
        loginButtonIcon: "${SECURITY_OAUTH2_DEFAULT_LOGIN_BUTTON_ICON:}"
        clientName: "${SECURITY_OAUTH2_DEFAULT_CLIENT_NAME:ClientName}"
        clientId: "${SECURITY_OAUTH2_DEFAULT_CLIENT_ID:}"
        clientSecret: "${SECURITY_OAUTH2_DEFAULT_CLIENT_SECRET:}"
        accessTokenUri: "${SECURITY_OAUTH2_DEFAULT_ACCESS_TOKEN_URI:}"
        authorizationUri: "${SECURITY_OAUTH2_DEFAULT_AUTHORIZATION_URI:}"
        scope: "${SECURITY_OAUTH2_DEFAULT_SCOPE:}"
        # Redirect URL that must be in sync with 'security.oauth2.loginProcessingUrl', but domain name added
        redirectUriTemplate: "${SECURITY_OAUTH2_DEFAULT_REDIRECT_URI_TEMPLATE:http://localhost:8080/login/oauth2/code/}"
        jwkSetUri: "${SECURITY_OAUTH2_DEFAULT_JWK_SET_URI:}"
        # 'authorization_code', 'implicit', 'refresh_token' or 'client_credentials'
        authorizationGrantType: "${SECURITY_OAUTH2_DEFAULT_AUTHORIZATION_GRANT_TYPE:authorization_code}"
        clientAuthenticationMethod: "${SECURITY_OAUTH2_DEFAULT_CLIENT_AUTHENTICATION_METHOD:post}" # basic or post
        userInfoUri: "${SECURITY_OAUTH2_DEFAULT_USER_INFO_URI:}"
        userNameAttributeName: "${SECURITY_OAUTH2_DEFAULT_USER_NAME_ATTRIBUTE_NAME:email}"
        mapperConfig:
          # Allows to create user if it not exists
          allowUserCreation: "${SECURITY_OAUTH2_DEFAULT_MAPPER_ALLOW_USER_CREATION:true}"
          # Allows user to setup ThingsBoard internal password and login over default Login window
          activateUser: "${SECURITY_OAUTH2_DEFAULT_MAPPER_ACTIVATE_USER:false}"
          # Mapper type of converter from external user into internal - 'basic' or 'custom'
          type: "${SECURITY_OAUTH2_DEFAULT_MAPPER_TYPE:basic}"
          basic:
            # Key from attributes of external user object to use as email
            emailAttributeKey: "${SECURITY_OAUTH2_DEFAULT_MAPPER_BASIC_EMAIL_ATTRIBUTE_KEY:email}"
            firstNameAttributeKey: "${SECURITY_OAUTH2_DEFAULT_MAPPER_BASIC_FIRST_NAME_ATTRIBUTE_KEY:}"
            lastNameAttributeKey: "${SECURITY_OAUTH2_DEFAULT_MAPPER_BASIC_LAST_NAME_ATTRIBUTE_KEY:}"
            # Strategy for generating Tenant from external user object - 'domain', 'email' or 'custom'
            # 'domain' - name of the Tenant will be extracted as domain from the email of the user
            # 'email' - name of the Tenant will email of the user
            # 'custom' - please configure 'tenantNamePattern' for custom mapping
            tenantNameStrategy: "${SECURITY_OAUTH2_DEFAULT_MAPPER_BASIC_TENANT_NAME_STRATEGY:domain}"
            # %{attribute_key} as placeholder for attribute value of attributes of external user object
            tenantNamePattern: "${SECURITY_OAUTH2_DEFAULT_MAPPER_BASIC_TENANT_NAME_PATTERN:}"
            # If this field is not empty, user will be created as a user under defined Customer
            # %{attribute_key} as placeholder for attribute value of attributes of external user object
            customerNamePattern: "${SECURITY_OAUTH2_DEFAULT_MAPPER_BASIC_CUSTOMER_NAME_PATTERN:}"
            # If this field is not empty, user will be created with default defined Dashboard
            defaultDashboardName: "${SECURITY_OAUTH2_DEFAULT_MAPPER_BASIC_DEFAULT_DASHBOARD_NAME:}"
            # If this field is set 'true' along with non-empty 'defaultDashboardName', user will start from the defined Dashboard in fullscreen mode
            alwaysFullScreen: "${SECURITY_OAUTH2_DEFAULT_MAPPER_BASIC_ALWAYS_FULL_SCREEN:false}"
          custom:
            url: "${SECURITY_OAUTH2_DEFAULT_MAPPER_CUSTOM_URL:}"
            username: "${SECURITY_OAUTH2_DEFAULT_MAPPER_CUSTOM_USERNAME:}"
            password: "${SECURITY_OAUTH2_DEFAULT_MAPPER_CUSTOM_PASSWORD:}"

database:
  ts_max_intervals: "${DATABASE_TS_MAX_INTERVALS:700}" # Max number of DB queries generated by single API call to fetch telemetry records
  ts:
    type: "${DATABASE_TS_TYPE:cassandra}" # cassandra, sql, or timescale (for hybrid mode, DATABASE_TS_TYPE value should be cassandra, or timescale)

# note: timescale works only with postgreSQL database for DATABASE_ENTITIES_TYPE.

# Cassandra driver configuration parameters
cassandra:
  # Thingsboard cluster name
  cluster_name: "${CASSANDRA_CLUSTER_NAME:InfinovaIoT Cluster}"
  # Thingsboard keyspace name
  keyspace_name: "${CASSANDRA_KEYSPACE_NAME:infinovaiot}"
  # Specify node list
  url: "${CASSANDRA_URL:10.82.27.90:9043}"
#  url: "${CASSANDRA_URL:10.82.27.21:30042}"
  # Enable/disable secure connection
  ssl: "${CASSANDRA_USE_SSL:false}"
  # Enable/disable JMX
  jmx: "${CASSANDRA_USE_JMX:false}"
  # Enable/disable metrics collection.
  metrics: "${CASSANDRA_USE_METRICS:false}"
  # NONE SNAPPY LZ4
  compression: "${CASSANDRA_COMPRESSION:none}"
  # Specify cassandra cluster initialization timeout in milliseconds (if no hosts available during startup)
  init_timeout_ms: "${CASSANDRA_CLUSTER_INIT_TIMEOUT_MS:300000}"
  # Specify cassandra claster initialization retry interval (if no hosts available during startup)
  init_retry_interval_ms: "${CASSANDRA_CLUSTER_INIT_RETRY_INTERVAL_MS:3000}"
  max_requests_per_connection_local: "${CASSANDRA_MAX_REQUESTS_PER_CONNECTION_LOCAL:32768}"
  max_requests_per_connection_remote: "${CASSANDRA_MAX_REQUESTS_PER_CONNECTION_REMOTE:32768}"
  # Credential parameters #
  credentials: "${CASSANDRA_USE_CREDENTIALS:false}"
  # Specify your username
  username: "${CASSANDRA_USERNAME:}"
  # Specify your password
  password: "${CASSANDRA_PASSWORD:}"

  # Cassandra cluster connection socket parameters #
  socket:
    connect_timeout: "${CASSANDRA_SOCKET_TIMEOUT:5000}"
    read_timeout: "${CASSANDRA_SOCKET_READ_TIMEOUT:20000}"
    keep_alive: "${CASSANDRA_SOCKET_KEEP_ALIVE:true}"
    reuse_address: "${CASSANDRA_SOCKET_REUSE_ADDRESS:true}"
    so_linger: "${CASSANDRA_SOCKET_SO_LINGER:}"
    tcp_no_delay: "${CASSANDRA_SOCKET_TCP_NO_DELAY:false}"
    receive_buffer_size: "${CASSANDRA_SOCKET_RECEIVE_BUFFER_SIZE:}"
    send_buffer_size: "${CASSANDRA_SOCKET_SEND_BUFFER_SIZE:}"

  # Cassandra cluster connection query parameters  #
  query:
    read_consistency_level: "${CASSANDRA_READ_CONSISTENCY_LEVEL:ONE}"
    write_consistency_level: "${CASSANDRA_WRITE_CONSISTENCY_LEVEL:ONE}"
    default_fetch_size: "${CASSANDRA_DEFAULT_FETCH_SIZE:2000}"
    # Specify partitioning size for timestamp key-value storage. Example: MINUTES, HOURS, DAYS, MONTHS,INDEFINITE
    ts_key_value_partitioning: "${TS_KV_PARTITIONING:MONTHS}"
    ts_key_value_ttl: "${TS_KV_TTL:0}"
    events_ttl: "${TS_EVENTS_TTL:0}"
    # Specify TTL of debug log in seconds. The current value corresponds to one week
    debug_events_ttl: "${DEBUG_EVENTS_TTL:604800}"
    buffer_size: "${CASSANDRA_QUERY_BUFFER_SIZE:200000}"
    concurrent_limit: "${CASSANDRA_QUERY_CONCURRENT_LIMIT:1000}"
    permit_max_wait_time: "${PERMIT_MAX_WAIT_TIME:120000}"
    dispatcher_threads: "${CASSANDRA_QUERY_DISPATCHER_THREADS:2}"
    callback_threads: "${CASSANDRA_QUERY_CALLBACK_THREADS:4}"
    poll_ms: "${CASSANDRA_QUERY_POLL_MS:50}"
    rate_limit_print_interval_ms: "${CASSANDRA_QUERY_RATE_LIMIT_PRINT_MS:1000}"
    # set all data types values except target to null for the same ts on save
    set_null_values_enabled: "${CASSANDRA_QUERY_SET_NULL_VALUES_ENABLED:false}"
    # log one of cassandra queries with specified frequency (0 - logging is disabled)
    print_queries_freq: "${CASSANDRA_QUERY_PRINT_FREQ:0}"
    tenant_rate_limits:
      enabled: "${CASSANDRA_QUERY_TENANT_RATE_LIMITS_ENABLED:false}"
      configuration: "${CASSANDRA_QUERY_TENANT_RATE_LIMITS_CONFIGURATION:1000:1,30000:60}"
      print_tenant_names: "${CASSANDRA_QUERY_TENANT_RATE_LIMITS_PRINT_TENANT_NAMES:false}"

# SQL configuration parameters
sql:
  # Specify batch size for persisting attribute updates
  attributes:
    batch_size: "${SQL_ATTRIBUTES_BATCH_SIZE:10000}"
    batch_max_delay: "${SQL_ATTRIBUTES_BATCH_MAX_DELAY_MS:100}"
    stats_print_interval_ms: "${SQL_ATTRIBUTES_BATCH_STATS_PRINT_MS:10000}"
  ts:
    batch_size: "${SQL_TS_BATCH_SIZE:10000}"
    batch_max_delay: "${SQL_TS_BATCH_MAX_DELAY_MS:100}"
    stats_print_interval_ms: "${SQL_TS_BATCH_STATS_PRINT_MS:10000}"
  ts_latest:
    batch_size: "${SQL_TS_LATEST_BATCH_SIZE:10000}"
    batch_max_delay: "${SQL_TS_LATEST_BATCH_MAX_DELAY_MS:100}"
    stats_print_interval_ms: "${SQL_TS_LATEST_BATCH_STATS_PRINT_MS:10000}"
  # Specify whether to remove null characters from strValue of attributes and timeseries before insert
  remove_null_chars: "${SQL_REMOVE_NULL_CHARS:true}"
  postgres:
    # Specify partitioning size for timestamp key-value storage. Example: DAYS, MONTHS, YEARS, INDEFINITE.
    ts_key_value_partitioning: "${SQL_POSTGRES_TS_KV_PARTITIONING:MONTHS}"
  timescale:
    # Specify Interval size for new data chunks storage.
    chunk_time_interval: "${SQL_TIMESCALE_CHUNK_TIME_INTERVAL:604800000}"
  ttl:
    ts:
      enabled: "${SQL_TTL_TS_ENABLED:true}"
      execution_interval_ms: "${SQL_TTL_TS_EXECUTION_INTERVAL:86400000}" # Number of milliseconds. The current value corresponds to one day
      ts_key_value_ttl: "${SQL_TTL_TS_TS_KEY_VALUE_TTL:0}" # Number of seconds
    events:
      enabled: "${SQL_TTL_EVENTS_ENABLED:true}"
      execution_interval_ms: "${SQL_TTL_EVENTS_EXECUTION_INTERVAL:86400000}" # Number of milliseconds. The current value corresponds to one day
      events_ttl: "${SQL_TTL_EVENTS_EVENTS_TTL:0}" # Number of seconds
      debug_events_ttl: "${SQL_TTL_EVENTS_DEBUG_EVENTS_TTL:604800}" # Number of seconds. The current value corresponds to one week

cache:
  # caffeine or redis
  type: "${CACHE_TYPE:redis}"

redis:
  # standalone or cluster
  connection:
    type: "${REDIS_CONNECTION_TYPE:standalone}"
  standalone:
    host: "${REDIS_HOST:10.82.27.15}"
    port: "${REDIS_PORT:6379}"
    useDefaultClientConfig: "${REDIS_USE_DEFAULT_CLIENT_CONFIG:false}"
    # this value may be used only if you used not default ClientConfig
    clientName: "${REDIS_CLIENT_NAME:standalone}"
    # this value may be used only if you used not default ClientConfig
    connectTimeout: "${REDIS_CLIENT_CONNECT_TIMEOUT:30000}"
    # this value may be used only if you used not default ClientConfig
    readTimeout: "${REDIS_CLIENT_READ_TIMEOUT:60000}"
    # this value may be used only if you used not default ClientConfig
    usePoolConfig: "${REDIS_CLIENT_USE_POOL_CONFIG:false}"
  cluster:
    # Comma-separated list of "host:port" pairs to bootstrap from.
    nodes: "${REDIS_NODES:}"
    # Maximum number of redirects to follow when executing commands across the cluster.
    max-redirects: "${REDIS_MAX_REDIRECTS:12}"
    useDefaultPoolConfig: "${REDIS_USE_DEFAULT_POOL_CONFIG:true}"
  # db index
  db: "${REDIS_DB:0}"
  # db password
  password: "${REDIS_PASSWORD:}"
  # pool config
  pool_config:
    maxTotal: "${REDIS_POOL_CONFIG_MAX_TOTAL:128}"
    maxIdle: "${REDIS_POOL_CONFIG_MAX_IDLE:128}"
    minIdle: "${REDIS_POOL_CONFIG_MIN_IDLE:16}"
    testOnBorrow: "${REDIS_POOL_CONFIG_TEST_ON_BORROW:true}"
    testOnReturn: "${REDIS_POOL_CONFIG_TEST_ON_RETURN:true}"
    testWhileIdle: "${REDIS_POOL_CONFIG_TEST_WHILE_IDLE:true}"
    minEvictableMs: "${REDIS_POOL_CONFIG_MIN_EVICTABLE_MS:60000}"
    evictionRunsMs: "${REDIS_POOL_CONFIG_EVICTION_RUNS_MS:30000}"
    maxWaitMills: "${REDIS_POOL_CONFIG_MAX_WAIT_MS:60000}"
    numberTestsPerEvictionRun: "${REDIS_POOL_CONFIG_NUMBER_TESTS_PER_EVICTION_RUN:3}"
    blockWhenExhausted: "${REDIS_POOL_CONFIG_BLOCK_WHEN_EXHAUSTED:true}"

# Actor system parameters
actors:
  rule:
    # Specify thread pool size for database request callbacks executor service
    db_callback_thread_pool_size: "${ACTORS_RULE_DB_CALLBACK_THREAD_POOL_SIZE:50}"
    # Specify thread pool size for javascript executor service
    js_thread_pool_size: "${ACTORS_RULE_JS_THREAD_POOL_SIZE:4}"
